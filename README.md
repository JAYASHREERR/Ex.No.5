## AIM

To test and compare how different prompting patterns (naïve vs. basic/refined prompts) influence the quality, accuracy, and depth of ChatGPT-generated responses across various test scenarios.

## AI TOOLS REQUIRED

ChatGPT / Any Generative AI Language Model

## EXPLANATION
Definition of Two Prompt Types
1. Naïve Prompt

Unstructured

Short and unclear

Lacks context

Does not specify instructions, tone, or output format

2. Basic / Refined Prompt

Clear and detailed

Structured with specific instructions

Provides context, constraints, expected format

Helps the AI understand exactly what the user wants

METHODOLOGY
Steps Followed

Select 5 different real test scenarios.

For each scenario, write a naïve prompt and a refined basic prompt.

Enter each prompt into ChatGPT and record the outputs.

Compare responses on:

Quality

Accuracy

Depth

Prepare an analysis table and summarize findings.

TEST SCENARIOS

We use 5 scenarios, each with Naïve Prompt, Basic Prompt, and Observed Output Comparison.

SCENARIO 1: Creative Story
Naïve Prompt

“Write a story.”

Basic Prompt

“Write a 200-word creative story about a lonely robot who finds a human friend.
Include emotions, conflict, and a happy ending. Maintain a hopeful tone.”

Difference Observed

Naïve output: Very short, bland plot.
Basic output: Rich storytelling, emotional depth, well-structured.

SCENARIO 2: Factual Answering
Naïve Prompt

“Tell me about the sun.”

Basic Prompt

“Explain the Sun in simple scientific terms in 5–6 lines.
Include:

Composition

Temperature

Importance for Earth

Energy production mechanism”

Difference Observed

Naïve output: Generic facts.
Basic output: Precise scientific explanation, clear structure.

SCENARIO 3: Summarization
Naïve Prompt

“Summarize photosynthesis.”

Basic Prompt

“Summarize the concept of photosynthesis in a single paragraph (5–6 sentences).
Include inputs, outputs, chemical equation, and importance to plants.”

Difference Observed

Naïve output: Only high-level summary.
Basic output: Detailed inputs/outputs, equation included, deeper explanation.

SCENARIO 4: Advice or Recommendations
Naïve Prompt

“How to study?”

Basic Prompt

“Give a structured study plan for college students preparing for exams.
Include:

Daily routine

Concentration tips

Revision strategy

Mistakes to avoid
Use bullet points.”

Difference Observed

Naïve output: General advice like “read books, revise.”
Basic output: Detailed, step-by-step plan with actionable tips.

SCENARIO 5: Content Writing
Naïve Prompt

“Write something about AI.”

Basic Prompt

“Write a well-structured 150-word paragraph on Artificial Intelligence covering:

Definition

Types

Applications

Benefits & risks
Use simple formal language.”

Difference Observed

Naïve output: Basic definition only.
Basic output: Covers multiple aspects and well-organized writing.

## RESULT
The prompt for the above experiment was executed successfully.
The results clearly show that basic/refined prompts consistently produce higher-quality, more accurate, and deeper responses compared to naïve prompts across all tested scenarios.
Thus, prompt clarity and structure significantly improve the performance of AI tools like ChatGPT.
